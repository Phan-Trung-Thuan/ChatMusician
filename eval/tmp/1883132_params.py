datasets = [
    [
        dict(
            abbr='lukaemon_mmlu_virology',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    type=
                    'opencompass.utils.text_postprocessors.first_capital_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about virology. Answer the question by replying A, B, C or D.\nQuestion: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    fix_id_list=[
                        0,
                        1,
                        2,
                        3,
                        4,
                    ],
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                'There is a single choice question about virology. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.FixKRetriever')),
            name='virology',
            path='./data/mmlu/',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_high_school_european_history',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    type=
                    'opencompass.utils.text_postprocessors.first_capital_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about high school european history. Answer the question by replying A, B, C or D.\nQuestion: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    fix_id_list=[
                        0,
                        1,
                        2,
                        3,
                        4,
                    ],
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                'There is a single choice question about high school european history. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.FixKRetriever')),
            name='high_school_european_history',
            path='./data/mmlu/',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            eval_cfg=dict(
                evaluator=dict(type='opencompass.datasets.HumanEvaluator'),
                k=[
                    1,
                    10,
                    100,
                ],
                pred_postprocessor=dict(
                    type='opencompass.datasets.humaneval_postprocess'),
                pred_role='BOT'),
            infer_cfg=dict(
                inferencer=dict(
                    max_out_len=512,
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'Complete the following python code:\n{prompt}',
                            role='HUMAN'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.ZeroRetriever')),
            path='openai_humaneval',
            reader_cfg=dict(
                input_columns=[
                    'prompt',
                ],
                output_column='task_id',
                train_split='test'),
            type='opencompass.datasets.HFDataset'),
        dict(
            abbr='lukaemon_mmlu_logical_fallacies',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    type=
                    'opencompass.utils.text_postprocessors.first_capital_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about logical fallacies. Answer the question by replying A, B, C or D.\nQuestion: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    fix_id_list=[
                        0,
                        1,
                        2,
                        3,
                        4,
                    ],
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                'There is a single choice question about logical fallacies. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.FixKRetriever')),
            name='logical_fallacies',
            path='./data/mmlu/',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_astronomy',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    type=
                    'opencompass.utils.text_postprocessors.first_capital_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about astronomy. Answer the question by replying A, B, C or D.\nQuestion: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    fix_id_list=[
                        0,
                        1,
                        2,
                        3,
                        4,
                    ],
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                'There is a single choice question about astronomy. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.FixKRetriever')),
            name='astronomy',
            path='./data/mmlu/',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_high_school_physics',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    type=
                    'opencompass.utils.text_postprocessors.first_capital_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about high school physics. Answer the question by replying A, B, C or D.\nQuestion: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    fix_id_list=[
                        0,
                        1,
                        2,
                        3,
                        4,
                    ],
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                'There is a single choice question about high school physics. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.FixKRetriever')),
            name='high_school_physics',
            path='./data/mmlu/',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_electrical_engineering',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    type=
                    'opencompass.utils.text_postprocessors.first_capital_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about electrical engineering. Answer the question by replying A, B, C or D.\nQuestion: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    fix_id_list=[
                        0,
                        1,
                        2,
                        3,
                        4,
                    ],
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                'There is a single choice question about electrical engineering. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.FixKRetriever')),
            name='electrical_engineering',
            path='./data/mmlu/',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_college_biology',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    type=
                    'opencompass.utils.text_postprocessors.first_capital_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about college biology. Answer the question by replying A, B, C or D.\nQuestion: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    fix_id_list=[
                        0,
                        1,
                        2,
                        3,
                        4,
                    ],
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                'There is a single choice question about college biology. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.FixKRetriever')),
            name='college_biology',
            path='./data/mmlu/',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_anatomy',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    type=
                    'opencompass.utils.text_postprocessors.first_capital_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about anatomy. Answer the question by replying A, B, C or D.\nQuestion: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    fix_id_list=[
                        0,
                        1,
                        2,
                        3,
                        4,
                    ],
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                'There is a single choice question about anatomy. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.FixKRetriever')),
            name='anatomy',
            path='./data/mmlu/',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_human_sexuality',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    type=
                    'opencompass.utils.text_postprocessors.first_capital_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about human sexuality. Answer the question by replying A, B, C or D.\nQuestion: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    fix_id_list=[
                        0,
                        1,
                        2,
                        3,
                        4,
                    ],
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                'There is a single choice question about human sexuality. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.FixKRetriever')),
            name='human_sexuality',
            path='./data/mmlu/',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_formal_logic',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    type=
                    'opencompass.utils.text_postprocessors.first_capital_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about formal logic. Answer the question by replying A, B, C or D.\nQuestion: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    fix_id_list=[
                        0,
                        1,
                        2,
                        3,
                        4,
                    ],
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                'There is a single choice question about formal logic. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.FixKRetriever')),
            name='formal_logic',
            path='./data/mmlu/',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_international_law',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    type=
                    'opencompass.utils.text_postprocessors.first_capital_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about international law. Answer the question by replying A, B, C or D.\nQuestion: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    fix_id_list=[
                        0,
                        1,
                        2,
                        3,
                        4,
                    ],
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                'There is a single choice question about international law. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.FixKRetriever')),
            name='international_law',
            path='./data/mmlu/',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_econometrics',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    type=
                    'opencompass.utils.text_postprocessors.first_capital_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about econometrics. Answer the question by replying A, B, C or D.\nQuestion: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    fix_id_list=[
                        0,
                        1,
                        2,
                        3,
                        4,
                    ],
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                'There is a single choice question about econometrics. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.FixKRetriever')),
            name='econometrics',
            path='./data/mmlu/',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
        dict(
            abbr='lukaemon_mmlu_machine_learning',
            eval_cfg=dict(
                evaluator=dict(
                    type='opencompass.openicl.icl_evaluator.AccEvaluator'),
                pred_postprocessor=dict(
                    type=
                    'opencompass.utils.text_postprocessors.first_capital_postprocess'
                )),
            infer_cfg=dict(
                ice_template=dict(
                    template=dict(round=[
                        dict(
                            prompt=
                            'There is a single choice question about machine learning. Answer the question by replying A, B, C or D.\nQuestion: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nAnswer: ',
                            role='HUMAN'),
                        dict(prompt='{target}\n', role='BOT'),
                    ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                inferencer=dict(
                    fix_id_list=[
                        0,
                        1,
                        2,
                        3,
                        4,
                    ],
                    type='opencompass.openicl.icl_inferencer.GenInferencer'),
                prompt_template=dict(
                    ice_token='</E>',
                    template=dict(
                        begin='</E>',
                        round=[
                            dict(
                                prompt=
                                'There is a single choice question about machine learning. Answer the question by replying A, B, C or D.\nQ: {input}\nA. {A}\nB. {B}\nC. {C}\nD. {D}\nA: ',
                                role='HUMAN'),
                        ]),
                    type=
                    'opencompass.openicl.icl_prompt_template.PromptTemplate'),
                retriever=dict(
                    type='opencompass.openicl.icl_retriever.FixKRetriever')),
            name='machine_learning',
            path='./data/mmlu/',
            reader_cfg=dict(
                input_columns=[
                    'input',
                    'A',
                    'B',
                    'C',
                    'D',
                ],
                output_column='target',
                train_split='dev'),
            type='opencompass.datasets.MMLUDataset'),
    ],
]
models = [
    dict(
        abbr='llama-2-7b-chat',
        batch_size=1,
        max_out_len=100,
        max_seq_len=2048,
        meta_template=dict(round=[
            dict(api_role='HUMAN', role='HUMAN'),
            dict(api_role='BOT', generate=True, role='BOT'),
        ]),
        path='./models/llama2/llama/llama-2-7b-chat/',
        run_cfg=dict(num_gpus=1, num_procs=1),
        tokenizer_path='./models/llama2/llama/tokenizer.model',
        type='opencompass.models.Llama2Chat'),
]
work_dir = './outputs/default/20231019_145446'
